# -*- coding: utf-8 -*-
"""task_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ts1_x6my4aRTkBl4LuWtXVaGJo-Iu6qC
"""

import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
device

# Create *known* parameters
weight = 0.7
bias = 0.3

# Create data
start = 0
end = 1
step = 0.02
X = torch.arange(start, end, step).unsqueeze(dim=1)
y = weight * X + bias

X[:10], y[:10]

# train/test split
train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing 
X_train, y_train = X[:train_split], y[:train_split]
X_test, y_test = X[train_split:], y[train_split:]

len(X_train), len(y_train), len(X_test), len(y_test)

# dataloader

from torch.utils.data import DataLoader
train_X= DataLoader(X_train,
    batch_size=5,   
    shuffle=True 
)
train_y= DataLoader(y_train,
    batch_size=5, 
    shuffle=True 
)

test_X= DataLoader(X_test,
    batch_size=5,
    shuffle=False 
)

test_y= DataLoader(y_test,
    batch_size=5,
    shuffle=False 
)

len(train_X), len(train_y), len(test_X), len(test_y)

from torch import nn

# Linear Regression model class
class LinearRegressionModel(nn.Module): 
    def __init__(self):
        super().__init__() 

        self.layer_1=nn.Linear(in_features=1, out_features=3)
        self.layer_2= nn.Linear(in_features=3, out_features=1)

    
    def forward(self, x: torch.Tensor) -> torch.Tensor: 
        # return self.weights * x + self.bias
        return self.layer_2(self.layer_1(x))
    

torch.manual_seed(42)

model_0 = LinearRegressionModel().to(device)
model_0

# loss function
loss_fn = nn.MSELoss() 

# optimizer
optimizer = torch.optim.SGD(params=model_0.parameters(), 
                            lr=0.01)

from timeit import default_timer as timer 
def print_train_time(start: float, end: float, device: torch.device = None):
    total_time = end - start
    print(f"Train time on {device}: {total_time:.3f} seconds")
    return total_time

torch.manual_seed(42)
train_time_start = timer()

epochs = 100

train_loss = 0 
test_loss = 0

for epoch in range(epochs):
  
    for batch in (train_X, train_y):
      ### Training
      X_train = X_train.to(device)
      y_train = y_train.to(device)
      model_0.train()

      # 1. Forward pass 
      y_pred = model_0(X_train)
      # print(y_pred)

      # 2. loss 
      loss = loss_fn(y_pred, y_train)

      # 3. Zero grad 
      optimizer.zero_grad()

      # 4. Loss backwards
      loss.backward()

      # 5. optimizer
      optimizer.step()

      ### Testing

      # evaluation mode
      model_0.eval()

      with torch.inference_mode():
          X_test = X_test.to(device)
          y_test = y_test.to(device)
          # 1. Forward pass 
          test_pred = model_0(X_test)

          # 2. loss 
          test_loss = loss_fn(test_pred, y_test)
        
      if epoch % 10 == 0:
        print(f"Epoch: {epoch} | MSE Train Loss: {loss} | MSE Test Loss: {test_loss} ")

train_time_end= timer()

# Calculate training time      

total_train_time_model_0 = print_train_time(start=train_time_start, 
                                           end=train_time_end,
                                           device=str(next(model_0.parameters()).device))

y_pred = X_train
print(y_pred.device)

