# -*- coding: utf-8 -*-
"""01_logistic_regressionipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yW33ECy6M8onE-qcMey-40-JbsY8HksE
"""

import torch
import torchvision
from torchvision.datasets import MNIST
from torchvision import transforms
from torchvision.transforms import ToTensor

## dataset
train_ds = MNIST(root ='data',
                train=True,
                download=True,
                transform=ToTensor(),
                target_transform=None)

test_ds=MNIST(
    root ='data', 
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None
    )

## dataloader
from torch.utils.data import DataLoader
train_dl = DataLoader(dataset = train_ds,
                      batch_size = 128,
                      shuffle = True)

test_dl = DataLoader(dataset = test_ds,
                      batch_size = 128,
                      shuffle = False)

# model
from torch import nn
class LogisticRegressionModel(nn.Module):
  def __init__(self):
    super().__init__()
    input_features = 28 * 28
    hidden_units = 28
    labels = 10
    ##hidden layer
    self.layer = nn.Sequential( nn.Linear(in_features= input_features, out_features = hidden_units),
                               nn.ReLU(),
                               nn.Linear(in_features= hidden_units, out_features = labels))

  def forward(self, x):
    x = x.reshape(-1, 784) 
    return self.layer(x)

torch.manual_seed(42)
model_0 = LogisticRegressionModel()

model_0

# train
loss_fn = nn.CrossEntropyLoss()
optimiser = torch.optim.SGD(params = model_0.parameters(), lr = 1e-5)

epochs = 100

for epoch in range(epochs):
  #training
  model_0.train()
  for batch in train_dl:
    image, labels = batch
    preds = model_0(image)
    loss = loss_fn(preds, labels)
    loss.backward()
    optimiser.step()
    optimiser.zero_grad()

  #testing
  model_0.eval()
  for batch in test_dl:
    image, labels = batch
    preds = model_0(image)
    test_loss = loss_fn(preds, labels)

  if epoch %10 == 0: 
    print(f"Epoch : {epoch} | Train Loss: {loss} | Test Loss: {test_loss}")

