# -*- coding: utf-8 -*-
"""CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mk-ZwEY6wGSw8-APJ1eD8ahr7QCsurtr
"""

import torch
import torchvision
from torchvision.datasets import CIFAR10
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor
from torch.utils.data import random_split
from torch import nn

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

# dataset
train_ds = CIFAR10(root = 'data',
                   train = True,
                   transform = ToTensor(),
                   target_transform = None,
                   download = True )

test_ds = CIFAR10(root = 'data',
                   train = False,
                   transform = ToTensor(),
                   target_transform = None,
                   download = True )

image, label = train_ds[0]
image.shape

len(train_ds), len(test_ds)

train_ds, val_ds = random_split(train_ds, [45000, 5000])
len(train_ds), len(val_ds), len(test_ds)

# dataloader

train_dl = DataLoader(dataset = train_ds,
                      batch_size = 128,
                      shuffle = True)

val_dl = DataLoader(dataset = train_ds,
                      batch_size = 128,
                      shuffle = False)


test_dl = DataLoader(dataset = train_ds,
                      batch_size = 128,
                      shuffle = False)

# model

class CIFAR10(nn.Module):
  def __init__(self):
    super().__init__()
    self.network = nn.Sequential(
        nn.Conv2d(3, 32, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2), # output: 64 x 16 x 16

        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2), # output: 128 x 8 x 8

        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2), # output: 256 x 4 x 4

        nn.Flatten(), 
        nn.Linear(256*4*4, 1024),
        nn.ReLU(),
        nn.Linear(1024, 512),
        nn.ReLU(),
        nn.Linear(512, 10)
    ) 

  def forward(self, x):
    return self.network(x)

# instance
model = CIFAR10().to(device)
model

image, label = train_ds[0]
image = image.to(device)
image, label

image.shape

# loss and optimiser
loss_fn = nn.CrossEntropyLoss()
optimiser = torch.optim.Adam(params = model.parameters(), lr = 0.001)
def acc_fn(preds, labels):
  n = nn.Softmax(dim=1)
  preds = n(preds)
  out = preds.argmax(dim=1)
  return torch.sum(out == labels) / len(labels)

from os import device_encoding
# train

epoch = 10

for i in range(epoch):

  model.train()
  train_loss = 0
  for batch in train_dl:
    image, label = batch
    image, label = image.to(device), label.to(device)

    # forward
    preds = model(image)
    # loss
    loss = loss_fn(preds, label)
    train_loss += loss 
    # zero_grad
    optimiser.zero_grad()
    # backpropogation
    loss.backward()
    # update
    optimiser.step()

  train_loss /= len(train_dl)

  model.eval()
  val_loss = 0
  val_acc = 0 
  with torch.inference_mode():
    for batch in val_dl:
      image, label = batch
      image, label = image.to(device), label.to(device)

      # forward
      preds = model(image)
      # loss
      val_loss += loss_fn(preds, label)
      val_acc += acc_fn(preds, label)

    val_loss /= len(val_dl)
    val_acc /= len(val_dl)

  print(f"Epoch: {i+1}, Train Loss: {train_loss : .3f}, Val Loss: {val_loss: .3f}, Val Acc: {val_acc: .3f}")

# test

with torch.inference_mode():
  for batch in test_dl:
    image, label = batch
    image, label = image.to(device), label.to(device)

    # forward
    preds = model(image)
    # loss
    val_loss += loss_fn(preds, label)
    val_acc += acc_fn(preds, label)

  val_loss /= len(val_dl)
  val_acc /= len(val_dl)

  print(f"Test Loss: {val_loss: .3f}, Test Acc: {val_acc: .3f}")