# -*- coding: utf-8 -*-
"""01_linear_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1no5N6SdvyuN3lJGHSnuotp6M6txNhWGP
"""

import numpy as np
import torch
print(torch.__version__)

# Input (temp, rainfall, humidity)
inputs = np.array([[73, 67, 43], 
                   [91, 88, 64], 
                   [87, 134, 58], 
                   [102, 43, 37], 
                   [69, 96, 70], 
                   [74, 66, 43], 
                   [91, 87, 65], 
                   [88, 134, 59], 
                   [101, 44, 37], 
                   [68, 96, 71], 
                   [73, 66, 44], 
                   [92, 87, 64], 
                   [87, 135, 57], 
                   [103, 43, 36], 
                   [68, 97, 70]], 
                  dtype='float32')

# Targets (apples, oranges)
targets = np.array([[56, 70], 
                    [81, 101], 
                    [119, 133], 
                    [22, 37], 
                    [103, 119],
                    [57, 69], 
                    [80, 102], 
                    [118, 132], 
                    [21, 38], 
                    [104, 118], 
                    [57, 69], 
                    [82, 100], 
                    [118, 134], 
                    [20, 38], 
                    [102, 120]], 
                   dtype='float32')

inputs = torch.from_numpy(inputs)
targets = torch.from_numpy(targets)

inputs, targets

from torch.utils.data import TensorDataset

# Define dataset
train_ds = TensorDataset(inputs, targets)
train_ds[0:3]

from torch.utils.data import DataLoader

# Define data loader
batch_size = 5
train_dl = DataLoader(train_ds, batch_size, shuffle=False)
# test_dl = DataLoader(test_ds, batch_size, shuffle=False)

for xb, yb in train_dl:
    print(xb)
    print(yb)
    break

from torch import nn
# Define model
# model = nn.Linear(3, 2)
# print(model.weight)
# print(model.bias)

class LinearRegressionModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.layer1 = nn.Linear(in_features= 3, out_features=2)

  def forward(self, x):
    return self.layer1(x) 

#instance
torch.manual_seed(42)
model = LinearRegressionModel()

# Parameters
model.state_dict()

# Generate predictions
preds = model(inputs)
preds

# Define loss function
loss_fn = nn.MSELoss()

# Define optimizer
optimiser = torch.optim.SGD(model.parameters(), lr=1e-10)

# training and testing loop
epochs =100

for epoch in range(epochs):
  model.train()
  for batch in train_dl:
    inputs, targets = batch
    # forward pass
    preds = model(inputs)
    # loss
    loss = loss_fn(preds, targets)
    # zero grad
    optimiser.zero_grad()
    # backward
    loss.backward()
    # update gradient
    optimiser.step()

  # model.eval()
  # with torch.inference_mode():
  #   for batch in test_dl:
  #     inputs, targets = batch
  #     # forward pass
  #     preds = model(inputs)
  #     # loss
  #     test_loss = loss_fn(preds, targets)

  if epoch %10 == 0: 
    print(f"Epoch : {epoch}  | Train Loss: {loss} ")

