# -*- coding: utf-8 -*-
"""03_pytorch_computer_vision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HkpEv_WTGcGRqlquFCCzW_BqB_kgPHKI

## 0. Computer vision libraries


*   torchvision

*   torchvision.Modules


*   torchvision.datasets


*   torchvision.transforms
"""

#import pytorch
import torch
from torch import nn

# import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor

# import matplotlib for visualisations
import matplotlib.pyplot as plt

# check version
print(torch.__version__)
print(torchvision.__version__)

"""## Getting a dataset
**FashionMNIST**



* root
* train
* download
* transform
* target_transform









"""

train_data=datasets.FashionMNIST(
    root ='data', 
    train=True,
    download=True,
    transform=ToTensor(),
    target_transform=None
    )  
test_data=datasets.FashionMNIST(
    root ='data', 
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None
    )

len(train_data), len(test_data)

# see the first training example

image, label = train_data[0]
image, label

class_name =train_data.classes
class_name

class_to_idx = train_data.class_to_idx
class_to_idx

train_data.targets

"""###1.1 Check input and otput shapes of data"""

image.shape, label

print(f"Image shape: {image.shape}")
print(f"Labels: {class_name[label]}")

"""### 1.2 Visualizing data"""

plt.imshow(image.squeeze())
plt.title(class_name[label])

plt.imshow(image.squeeze(), cmap='gray')
plt.title(class_name[label])

#plot more images
image_1, label_1 = train_data[2]
image_1, label_1

plt.imshow(image_1.squeeze(), cmap='gray')
plt.title(class_name[label_1])
plt.axis(False)

#plot more images
torch.manual_seed(42)
fig = plt.figure(figsize=(9, 9))
rows, cols=4, 4
for i in range(1, rows*cols+1):
  random_idx=torch.randint(0, len(train_data), size=[1]).item()
  print(random_idx)
  image, label = train_data[random_idx]
  fig.add_subplot(rows, cols, i)
  plt.imshow(image.squeeze(), cmap='gray')
  plt.title(class_name[label])
  plt.axis(False)

"""##2. DataLoader

turn dataset into python iterable

we can turn our data into batches (or mini_batches)

"""

from torch.utils.data import DataLoader
train_dataloader=DataLoader(dataset=train_data,
                            batch_size=32,
                            shuffle=True)
test_dataloader=DataLoader(dataset=test_data,
                            batch_size=32,
                            shuffle=False)

train_dataloader, test_dataloader

print(f"Dataloaders:{train_dataloader, test_dataloader} ")
len(train_dataloader), len(test_dataloader)

1875 * 32, 313 * 32

# Check out what's inside the training dataloader
train_features_batch, train_labels_batch = next(iter(train_dataloader))
train_features_batch.shape, train_labels_batch.shape

# show a sample
torch.manual_seed(42)
random_idx = torch.randint(1, len(train_features_batch), size=[1]).item()
img, label = train_features_batch[random_idx], train_labels_batch[random_idx]
plt.imshow(img.squeeze(), cmap='gray')
plt.title(class_name[label])
plt.axis(False)

"""##3. Model 0: Baseline model"""

# create a flatten layer
flatten_model = nn.Flatten()

# get a single sample
x= train_features_batch[0]
x.shape

#flatten the model
output = flatten_model(x)
output.shape

output = output.squeeze()
output

class FashionMNISTModelV0(nn.Module):
  def __init__(self, input_shape: int, hidden_units : int, output_shape : int):
    super().__init__()
    self.layer_stack=nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = input_shape, 
                  out_features = hidden_units),
        nn.Linear(in_features = hidden_units, 
                  out_features = output_shape)
    )

  def forward(self, x):
    return self.layer_stack(x)

torch.manual_seed(42)

model_0 = FashionMNISTModelV0(
    input_shape = 28 * 28,
    hidden_units= 10,
    output_shape= len(class_name)
)

model_0

dummy_x = torch.randn([1, 1, 28, 28])
model_0(dummy_x).shape

# loss func and optimizer

loss_fn = nn.CrossEntropyLoss()
optimizer= torch.optim.SGD(params= model_0.parameters(), lr= 0.1)

# train loop and test loop
## 1. loop through epochs
## 2. loop through training batches, calculate the train loss per bath
## 3. loop though testing batches, calculate the test loss per batch

# import tqdm => progress bar
from tqdm.auto import tqdm

epochs =7
for epoch in range(epochs): 
  print(f"Epochs: {epoch}")

  ### training 
  train_loss=0

  #loop through training batches
  for batch, (X, y) in enumerate(train_dataloader):
    model_0.train()
    # 1. forward pass
    y_pred = model_0(X)

    # 2. loss func
    loss = loss_fn(y_pred, y)
    train_loss+=loss
    # 3. optimizer zero_grad
    optimizer.zero_grad()
    # 4. backward func
    loss.backward()
    # 5. optimiser_step 
    optimizer.step()

    # Print out how many samples have been seen
    if batch % 400 == 0:
      print(f"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples")
  
  train_loss = train_loss / len(train_dataloader)

  ### Testing
  test_loss = 0

  model_0.eval()
  with torch.inference_mode():
    for X, y in test_dataloader:
      # 1. forward pass
      test_pred = model_0(X)
      # 2. loss func
      loss = loss_fn(test_pred, y)
      test_loss+=loss
    
    test_loss = test_loss / len(test_dataloader)
  
  ## Print out what's happening
  print(f"\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}")

"""## 4. Predictions"""

torch.manual_seed(42)
def eval_model(model: torch.nn.Module, 
               data_loader: torch.utils.data.DataLoader, 
               loss_fn: torch.nn.Module):
   
    loss = 0
    model.eval()
    with torch.inference_mode():
        for X, y in data_loader:
            # Make predictions with the model
            y_pred = model(X)
            
            # Accumulate the loss values per batch
            loss += loss_fn(y_pred, y)
        
        # Scale loss and acc to find the average loss per batch
        loss /= len(data_loader)
        
    return {"model_name": model.__class__.__name__, # only works when model was created with a class
            "model_loss": loss.item()}

# Calculate model 0 results on test dataset
model_0_results = eval_model(model=model_0, data_loader=test_dataloader,
    loss_fn=loss_fn
)
model_0_results